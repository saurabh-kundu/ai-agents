{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44186a33",
   "metadata": {},
   "source": [
    "This is a notebook responsible for interacting with Ollama (llama3.3 model in particular) to orchestrate a series of tasks.\n",
    "\n",
    "Python\n",
    "UV package manager\n",
    "OpenAI library\n",
    "Ollama (llama3.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a28faeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using openAI libraries\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "ollama = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "model_name = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ebce44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm here to help you with any questions or tasks you may have. What's on your mind? Do you need help with something specific, or do you just want to chat? I'm all ears!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"You are a helpful assistant that can answer questions and help with tasks.\"\n",
    "message = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=message,\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
